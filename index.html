<style>
body {
  margin-top: 30px;
  margin-bottom: 30px;
  margin-left: 220px;
  margin-right: 220px;
}
</style>

<head>
<title>杨佳琪</title>
<link rel="stylesheet" type="text/css" href="resources/main.css">
</head>

<body>

<table>
<tr>
<td><img src="images/yjq.png" width="200"></td>

<td>
<div style="font-size:24; font-weight:bold">Jiaqi Yang</div>
<div>
Northwestern Polytechnical University,school of Computer Science<br/>
Associate Professor<br/>
PhD Superviser <br/>

</div>
<div>
Email: jqyang AT nwpu.edu.cn
</div>
<div>
<br>
<!-- <a href="#Research">[Research]</a>&nbsp; -->
<a href="#publications">[Publications]</a>&nbsp;
<a href="#education">[Education]</a>&nbsp;
<a href="#experiences">[Experiences]</a>&nbsp;
<a href="#Service">[Service]</a>&nbsp;
<a href="#talks">[Talks]</a>&nbsp;
<!-- <a href="#Teaching">[Teaching]</a>&nbsp; -->
<br>
<a href="https://scholar.google.com/citations?user=d6l7980AAAAJ&hl=en" target="_blank">[Google Scholar]</a>&nbsp;

</div>
</td>
</tr>
</table>

<script type="text/javascript">
function hideshow(which){
if (!document.getElementById)
return
if (which.style.display=="block")
which.style.display="none"
else
which.style.display="block"
}
</script>


<div class="section">
  <p>
    杨佳琪，西北工业大学计算机学院长聘副教授，博导。他担任空天地海一体化大数据应用技术国家工程实验室多域多维信息系统方向负责人、中国图象图形学学会三维视觉专委会（CSIG-3DV）秘书、陕西省电子信息类专业共同体电信类工作委员会秘书长。
    主要研究方向为计算资源、数据标签受限条件下的三维配准重建，致力于提出航天应用背景下的无需训练、适配全国产化平台、轻量化的三维重建算法。近年在IEEE TPAMI、CVPR等CCF A/IEEE汇刊/中科院一区的期刊会议发表论文30余篇，
    包括CVPR 2023 best student paper。主持国家自然科学基金、国防纵向重点项目等国家级项目5项、陕西省自然基金等省部级项目3项；参与国防纵向重点项目等国家级项目10余项，成果应用于航天领域空间环境三维重建感知。
    <br><br>

    I lead 3D vision group in Area-Space-Ground-Oceans (ASGO) National Engineering Laboratory in Northwestern Polytechnical University (NWPU).
    Our research interests include:
    1) 3D reconstruction from point clouds;
    2) 3D reconstruction from images; 
    3) Point cloud vision tasks. 
  </p>
  
  <p><b style="color: green; background-color: #ffff42">NEW</b> We have 2 papers accepted to ICCV 2023. See you in Paris!</p>
  </div>

<br>



<!-- <a name="research"></a>
<div class="section">
<h3>research</h3>
<ul>
<li>研究方向:三维视觉(3D computer vision)>尤其是：三维重建</li>
<ul>
<li>2D->3D:基于图像(序列)的三维重建</li>

<li>2.5D->3D: 基于点云配准的三维重建</li>

<li>3D理解:三维语义分析与理解</li>
</ul>


<li>技术途径：纯几何、几何+深度学习、无监督深度学习。</li>

<li>应用领域：我们生活在一个三维的世界，三维重建的需求几乎无处不在。</li>
<b>
<li>学生培养理念</li>
<ul>
  <li>站在学生立场，引导学生兴趣驱动，培养“挖掘科学问题-解决科学问题-成果发表”能力，全程陪跑每位学生每个科研工作。</li>
  <li>本人会为每一位同学制定详实的研究计划，不让学生存在科研迷茫期。</li>
</ul>
</b>


<li>招生</li>
<ul>
<li>组里每位同学都有高水平论文等成果,“三维”气氛浓厚,欢迎考生联系: jqyang@nwpu.edu.cn <a href="https://teacher.nwpu.edu.cn/ynzhang.html">,团队（张艳宁教授，三项国家级平台负责人）联系方式点击这里</a>
</li>
<li>
每年招收3-5名大二、大三本科实习生
</li>
</ul>


<li><p style="color:red; font-weight:bold;">指导学生情况</p></li>
<ul>
<li>
<p style="color:red; font-weight:bold;">指导硕士研究生,在研一发表TPAMI、CVPR (泛AI领域影响力最高的期刊和会议)两篇;</p>
</li>

<li>
<p style="color:red; font-weight:bold;">指导硕士研究生,获得CVPR 2023最佳学生论文奖,中国23年以国内高校唯一单位首次获奖;</p>
</li>

<li>
<p style="color:red; font-weight:bold;">硕士去向:AI公司算法岗65w+年薪、海外高校读博等;</p>
</li>

<li>
<p style="color:red; font-weight:bold;">硕士国奖率50%(截止2023年);</p>
</li>

<li>
<p style="color:red; font-weight:bold;">已毕业硕士，均达到西工大学术性博士毕业学术成果计分要求;</p>
</li>
</ul>

</ul>
</ul>
</div>
<br> -->



<a name="publications"></a>
<div class="mainsection">
<h3>Publications</h3>
<table width="100%">

<!-- Mutual Voting -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Mutual-Voting.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/abstract/document/10105460">Mutual Voting for Ranking 3D Correspondences</a></b><i>
  <br><b>
  IEEE Transactions on Pattern Analysis and Machine Intelligence 2023</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff"> (CCF A,1st ranking AI journal) </b>   -->
</i><br>
<b>Jiaqi Yang</b>, Xiyu Zhang, Shichao Fan, Chunlin Ren, Yanning Zhang
<p> </p>
<!-- paper link -->
<a href="https://ieeexplore.ieee.org/abstract/document/10105460">[paper]</a>  /
<!-- code link -->
<a href="https://github.com/NWPU-YJQ-3DV/2022_Mutual_Voting">[code]</a> 
<br><br>




<br><br>
<!-- A Performance Evaluation -->
<tr>
<td width="25%" valign="top"><p><img src="paper/A-Performance-Evaluation.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/1907.02890">A Performance Evaluation of Correspondence Grouping Methods for 3D Rigid Data Matching
</a></b><i>
<br><b>
IEEE Transactions on Pattern Analysis and Machine Intelligence 2021</b>
<!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff"> (CCF A,1st ranking AI journal) </b>   -->
</i><br>
<b> Jiaqi Yang</b>, Ke Xian, Peng Wang, Yanning Zhang
<p> </p>
<a href="https://arxiv.org/pdf/1907.02890.pdf">[paper]</a> 
<br><br>



<!-- 3D Registration with Maximal Cliques -->
<tr>
<td width="25%" valign="top"><p><img src="paper/3D-Registration-with-Maximal-Cliques.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/2305.10854">3D Registration with Maximal Cliques</a></b><i>
  <br><b>  
  CVPR 2023
  <b style="color: rgb(255, 0, 0); background-color: #ffffff">
(Best Student Paper) </b></b>
</i><br>
Xiyu Zhang, <b>Jiaqi Yang*</b>, Shikun Zhang, Yanning Zhang

<p></p>
<a href="https://arxiv.org/abs/2305.10854.pdf">[paper] /
<!-- code link -->
<a href="https://github.com/zhangxy0517/3D-Registration-with-Maximal-Cliques">[code]</a> 
<br><br>


<!-- MixCycle: Mixup Assisted Semi-Supervised 3D Single Object Tracking with Cycle Consistency -->
<tr>
  <td width="25%" valign="top"><p><img src="paper/MixCycle-Mixup-Assisted-Semi-Supervised-3D-Single-Object-Tracking-with-Cycle-Consistency.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
  <td width="75%" valign="top"><p>
  <b><a href="https://arxiv.org/abs/2303.09219">MixCycle: Mixup Assisted Semi-Supervised 3D Single Object Tracking with Cycle Consistency</a></b><i>
    <br><b>  
    ICCV 2023</b>
    <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff"> -->
  <!-- (Best Student Paper) </b></b> -->
  </i><br>
  Qiao Wu, <b>Jiaqi Yang*</b>, Kun Sun, Chuai Zhang, Yanning Zhang, Mathieu Salzmann
  
  <p></p>
  <a href="https://arxiv.org/abs/2303.09219.pdf">[paper] 
  <!-- code link -->
  <!-- <a href="https://github.com/zhangxy0517/3D-Registration-with-Maximal-Cliques">[code]</a>  -->
  <br><br>



<!-- Hierarchical Prior Mining for Non-local Multi-View Stereo -->
<tr>
  <td width="25%" valign="top"><p><img src="paper/Hierarchical-Prior-Mining-for-Non-local-Multi-View-Stereo.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
  <td width="75%" valign="top"><p>
  <b><a href="https://arxiv.org/abs/2303.09758">Hierarchical Prior Mining for Non-local Multi-View Stereo</a></b><i>
    <br><b>  
    ICCV 2023</b>
    <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff"> -->
  <!-- (Best Student Paper) </b></b> -->
  </i><br>
  Chunlin Ren, Qingshan Xu, Shikun Zhang, <b>Jiaqi Yang*</b>
  
  <p></p>
  <a href="https://arxiv.org/pdf/2303.09758.pdf">[paper] 
  <!-- code link -->
  <!-- <a href="https://github.com/zhangxy0517/3D-Registration-with-Maximal-Cliques">[code]</a>  -->
  <br><br>





<!-- Evaluating Local Geometric Feature Representations for 3D Rigid Data Matching -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Evaluating-Local-Geometric.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/1907.00233">Evaluating Local Geometric Feature Representations for 3D Rigid Data Matching</a></b>
 <i><br><b>  
  IEEE Transactions on Image Processing 2020</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(CCF A,中科院1区top)</b> -->
 </i><br>
<b>Jiaqi Yang</b>, Siwen Quan, Peng Wang, Yanning Zhang<br>
<p> </p>

<a href="https://arxiv.org/abs/1907.00233.pdf">[paper]</a> /
<!-- code link -->
<a href="https://github.com/zhangxy0517/3D-Registration-with-Maximal-Cliques">[code]</a> 
<br><br>


<!-- Toward the Repeatability and Robustness of the Local Reference Frame for 3D Shape Matching: An Evaluation -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Toward-the-Repeatability-and-Robustness.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="50%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/8345152">Toward the Repeatability and Robustness of the Local Reference Frame for 3D Shape Matching: An Evaluation</a></b>
<i><br><b>IEEE Transactions on Image Processing 2018</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">
    (CCF A,中科院1区top)</b> -->
</i><br>
<b>Jiaqi Yang</b>, Yang Xiao, Zhiguo Cao
<p></p>
<a href="https://ieeexplore.ieee.org/document/8345152">[paper]</a> 
<br><br>



<!-- Image feature correspondence selection: a comparative study and a new contribution -->

<tr>
<td width="25%" valign="top"><p><img src="paper/Image-feature-correspondence.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/abstract/document/8949766">Image feature correspondence selection: a comparative study and a new contribution</a></b>
<i><br><b>IEEE Transactions on Image Processing 2020</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">
    (CCF A,中科院1区top)</b> -->
 </i><br>
 Chen Zhao, Zhiguo Cao, <b>Jiaqi Yang</b>, Ke Xian, Xin Li<br>

 <p> </p>
<a href="https://ieeexplore.ieee.org/abstract/document/8949766">[paper]</a> 
<br><br>


<!-- NM-Net: Mining reliable neighbors for robust feature correspondences -->
<tr>
<td width="25%" valign="top"><p><img src="paper/NM-Net.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/1904.00320">NM-Net: Mining reliable neighbors for robust feature correspondences</a></b>
<i><br><b>CVPR 2019</b>
  <b style="color: rgb(255, 0, 0); background-color: #ffffff"> 
(CCF A,Oral ,<5% acceptance rate) </b>
</i><br>
Chen Zhao, Zhiguo Cao, Chi Li, Xin Li, <b>Jiaqi Yang*</b><br>
<p> </p>
<a href="https://arxiv.org/abs/1904.00320.pdf">[paper]</a> /
<a href="https://github.com/sailor-z/NM-Net">[code]</a>
<br><br>


<!-- PhyIR: Physics-based Inverse Rendering for Panoramic Indoor Images -->
<tr>
<td width="25%" valign="top"><p><img src="paper/PhyIR.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/9879361">PhyIR: Physics-based Inverse Rendering for Panoramic Indoor Images</a></b>
<i><br><b>CVPR 2022</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">
    (CCF A) </b> -->
</i><br>
Zhen Li, Lingli Wang, Xiang Huang, Cihui Pan*, <b>Jiaqi Yang*</b> <br>
<p> </p>
<a href="https://ieeexplore.ieee.org/document/9879361">[paper]</a>
<br><br>


<!-- Multi-view Inverse Rendering for Large-scale Real-world Indoor Scenes -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Multi-view-Inverse-Rendering-now.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/2211.10206">Multi-view Inverse Rendering for Large-scale Real-world Indoor Scenes</a></b>
<i><br><b>CVPR 2023</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">  (CCF A) </b> -->
</i><br>
Zhen Li, Lingli Wang, Mofang Cheng, Cihui Pan*, <b>Jiaqi Yang*</b>
<br>
<p> </p>
<a href="https://arxiv.org/abs/2211.10206.pdf">[paper]</a> 
<a href="https://github.com/LZleejean/TexIR_code">[code]</a>
<br><br>


<!-- Unsupervised Learning of 3D Semantic Keypoints with Mutual Reconstruction -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Unsupervised-Learning.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/2203.10212">Unsupervised Learning of 3D Semantic Keypoints with Mutual Reconstruction</a></b>
<i><br><b>ECCV 2022</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">
    (视觉三大顶会之一，一作为组内实习大三本科生)</b>   -->
</i><br>
Haochen Yuan, Chen Zhao, Shichao Fan, Jiaxi Jiang, <b>Jiaqi Yang*</b>
<br>
<p> </p>

<a href="https://arxiv.org/abs/2203.10212.pdf">[paper]</a> 
<br><br>

<!-- 注意这里br可以增加间距 -->



<!-- Learning to Fuse Local Geometric Features for 3D Rigid Data Matching -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Learning-to-fuse-local-geometric-features.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/1904.12099">Learning to Fuse Local Geometric Features for 3D Rigid Data Matching</a></b>
<i><br><b>Information Fusion 2020</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff"> (IF=10.716,中科院1区top)  </b>   -->
</i><br>
<b>Jiaqi Yang</b>, Chen Zhao, Ke Xian, Angfan Zhu, Zhiguo Cao<br>

<p></p>

<a href="https://arxiv.org/abs/1904.12099.pdf">[paper]</a> 
<br><br>


<!-- RANSACs for 3D Rigid Registration: A Comparative Evaluation -->
<tr>
<td width="25%" valign="top"><p><img src="paper/A-Comparative-Evaluation.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/9754326">RANSACs for 3D Rigid Registration: A Comparative Evaluation</a></b>
<i><br><b>IEEE/CAA Journal of Automatica Sinica(自动化学报 英文版) 2022</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff"> (中科院1区 top)</b>   -->
</i><br>
<b>Jiaqi Yang</b>, Zhiqiang Huang, Siwen Quan, Yanning Zhang, Zhiguo Cao
<br>
<p> </p>
<a href="https://ieeexplore.ieee.org/document/9754326">[paper]</a> 

<br><br>




<!-- SAC-COT: Sample Consensus by Sampling Compatibility Triangles in Graphs for 3-D Point Cloud Registration -->
<tr>
<td width="25%" valign="top"><p><img src="paper/SAC-COT.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/9362271">SAC-COT: Sample Consensus by Sampling Compatibility Triangles in Graphs for 3-D Point Cloud Registration</a></b>
<i><br><b>IEEE Transactions on Geoscience and Remote Sensing 2021</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区, ESI高被引)  </b>   -->
</i><br>
<b>Jiaqi Yang</b>, Zhiqiang Huang, Siwen Quan, Zhaoshuai Qi, Yanning Zhang<br>
<p> </p>
<a href="https://ieeexplore.ieee.org/document/9362271">[paper]</a> 
<br><br>




<!-- Correspondence Selection with Loose-tight Geometric Voting for 3D Point Cloud Registration -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Correspondence-Selection.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/9676593">Correspondence Selection with Loose-tight Geometric Voting for 3D Point Cloud Registration</a></b>
<i><br><b>IEEE Transactions on Geoscience and Remote Sensing 2022</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区) </b> -->
</i><br>
<b>Jiaqi Yang</b>, Jiahao Chen, Siwen Quan, Wei Wang, Yanning Zhang<br>
<p> </p>
<a href="https://ieeexplore.ieee.org/document/9676593">[paper]</a> /
<a href="https://github.com/chenjiahao24/LT-GV">[code]</a>
<br><br>


<!-- Compatibility-Guided Sampling Consensus for 3-D Point Cloud Registration -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Compatibility-Guided-Sampling-Consensus.jpg" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/9052691">Compatibility-Guided Sampling Consensus for 3-D Point Cloud Registration</a></b>
<i><br><b>IEEE Transactions on Geoscience and Remote Sensing 2020</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区)   </b>       -->
</i><br>
Siwen Quan, <b>Jiaqi Yang*</b>
<p></p>
<a href="https://ieeexplore.ieee.org/document/9052691">[paper]</a> 
<br><br>



<!-- Toward Efficient and Robust Metrics for RANSAC Hypotheses and 3D Rigid Registration -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Toward-Efficient-and-Robust-Metrics.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/9366498">Toward Efficient and Robust Metrics for RANSAC Hypotheses and 3D Rigid Registration</a></b>
<i><br><b>IEEE Transactions on Circuits and Systems for Video Technology 2021</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区)   </b>     -->
</i><br>
<b>Jiaqi Yang</b>, Zhiqiang Huang, Siwen Quan, Qian Zhang, Yanning Zhang, Zhiguo Cao<br>
<p></p>
<a href="https://ieeexplore.ieee.org/document/9366498">[paper]</a> 
<br><br>


<!-- Aligning 2.5D scene fragments with distinctive local geometric features and voting-based correspondences -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Aligning-2.5D-Scene-Fragments.png" width="250" height="150" height="130" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://ieeexplore.ieee.org/document/8307430">Aligning 2.5D scene fragments with distinctive local geometric features and voting-based correspondences</a></b>
<i><br><b>IEEE Transactions on Circuits and Systems for Video Technology 2019</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区)   </b>  -->
</i><br>
<b>Jiaqi Yang</b>, Yang Xiao, Zhiguo Cao<br>
<p></p>
<a href="https://ieeexplore.ieee.org/document/8307430">[paper]</a> 
<br><br>


<!-- Rotation invariant point cloud analysis: Where local geometry meets global topology -->
<tr>
<td width="25%" valign="top"><p><img src="paper/Rotation-invariant-point-cloud-analysis.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://arxiv.org/abs/1911.00195">Rotation invariant point cloud analysis: Where local geometry meets global topology</a></b>
<i><br><b>Pattern Recognition 2022</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区)</b>  -->
</i><br>
Chen Zhao, <b>Jiaqi Yang</b>, Xin Xiong, Angfan Zhu, Zhiguo Cao, Xin Li<br>
<!-- <p>Proposed several novel algorithms to craft adversarial point clouds against 3D deep learning models with adversarial points perturbation and adversarial points generation.</p> -->
<p></p>
<a href="https://arxiv.org/abs/1911.00195.pdf">[paper]</a> /
<a href="https://github.com/sailor-z/LGR-Net">[code]</a>
<br><br>


<!-- TOLDI: An effective and robust approach for 3D local shape description -->
<tr>
  <td width="25%" valign="top"><p><img src="paper/TOLDI.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
  <td width="75%" valign="top"><p>
  <b><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320316303776">TOLDI: An effective and robust approach for 3D local shape description</a></b>
  <i><br><b>Pattern Recognition 2022</b>
    <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区)</b>  -->
  </i><br>
  Chen Zhao, <b>Jiaqi Yang</b>, Xin Xiong, Angfan Zhu, Zhiguo Cao, Xin Li<br>
  <!-- <p>Proposed several novel algorithms to craft adversarial point clouds against 3D deep learning models with adversarial points perturbation and adversarial points generation.</p> -->
  <p></p>
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320316303776">[paper]</a> 
  <br><br>




<!-- The effect of spatial information characterization on 3D local feature descriptors: A quantitative evaluation -->
<tr>
<td width="25%" valign="top"><p><img src="paper/The-effect-of-spatial-information-characterization.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320317300183">The effect of spatial information characterization on 3D local feature descriptors: A quantitative evaluation</a></b>
<i><br><b>Pattern Recognition 2017</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区)</b>  -->
</i><br>
<b>Jiaqi Yang</b>, Qian Zhang, Zhiguo Cao<br>
<!-- <p> We studied how to parallelize training of deep convolutional networks beyond simple data or model parallelism. Proposed a layer-wise parallelism that allows each layer in a network to use an individual parallelization strategy.</p> -->
<p></p>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320317300183">[paper]</a> 
<br><br>


<!-- A fast and robust local descriptor for 3D point cloud registration -->
<tr>
<td width="25%" valign="top"><p><img src="paper/A-fast-and-robust-local-descriptor.png" width="250" height="150" alt="" style="border-style: none" align="top"></p></td>
<td width="75%" valign="top"><p>
<b><a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025516300378">A fast and robust local descriptor for 3D point cloud registration</a></b>
<i><br><b>Information Sciences 2016</b>
  <!-- <b style="color: rgb(255, 0, 0); background-color: #ffffff">(中科院1区)</b>  -->
</i><br>
<b>Jiaqi Yang</b>, Zhiguo Cao, Qian Zhang<br>
<!-- <p>Proposed a novel framework for 3D object detection with image region proposals (lifted to 3D frustums) and PointNets. Our method is simple, efficient and effective, ranking at <i>first place</i> for <a href="http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d">KITTI 3D object detection benchmark</a> on all categories (11/27/2017).</p> -->
<p></p>
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025516300378">[paper]</a> 
<br><br>

</table>
</ul>
</div>
<br>

<a name="education"></a>
<div class="section">
<h3>Education</h3>
<ul>
<li>2010.9 - 2014.7: B.Eng. in Automation, Huazhong University of Science and Technology</li>
<li>2017.9 - 2018.9: CSC-PhD. in GRASP Lab, University of Pennsylvania</li>
<li>2014.9 - 2019.7: PhD. in Automation, Huazhong University of Science and Technology (<a href="http://faculty.hust.edu.cn/caozhiguo1/zh_CN/index.htm">Supervisor:Zhiguo Cao</a>)</li>

</ul>
</div>
<br>

<a name="experiences"></a>
<div class="section">
<h3>Experiences</h3>
<ul>
<li>2019.7 - 2023.5:  Northwestern Polytechnical University,school of Computer Science, Assistant Professor Supervisor of Master</li>
<li>2023.5 - now:  Northwestern Polytechnical University,school of Computer Science, Associate Professor PhD Superviser</li>

</ul>
</div>
<br>



<a name="service"></a>
<div class="section">
<h3>Service</h3>
<ul>
<li> Secretary of CSIG-3DV <a href="https://csig3dv.cn/">(website)</a> 

<li> Secretary-General of the Telecommunications Working Committee of Shaanxi Provincial Electronic Information Professional Community</li>

<li> China3DV 2023 Chairman of the Organization Committee</li>

<li>China3DV 2021  Chairman of Poster</li>

<li>Propaganda Chairman of the 4th National SLAM Technology Forum</li>

<li>Sensors、Visual Intelligence Guest Editor</li>

</div>






<a name="talks"></a>
<div class="section">
<h3>Talks</h3>
<ul>
<li>
Invited Speaker. Jittor forum,2023.07


<li>
Invited Speaker. CSIG Walking into Colleges and Universities, “ Walk into Tianjin University of Technology ”, 2023.07</li>


<li>
Invited Speaker. VALSE 2023, 3DV workshop. 2023.06</li>

<li>
Invited Speaker. China3DV Young Scientists Forum: 3D Vision in Aerospace, 2021.06</li>


<li>
Invited Speaker. GAMES Webinar 232th, " Revisiting Geometric Methods for 3D Point Cloud Registration ", 2022.06</li>
</ul>
</div>


<!-- <a name="teaching"></a>
<div class="section">
<h3>Teaching</h3>
<ul>
<li>
《三维视觉:理论及应用》,授课教师:杨佳琪,32学时,专业选修课,每年秋季学期,授课对象:全校本科生</li>


<li>
《计算机视觉中的深度学习》,授课教师:王鹏,杨佳琪,40学时,专业选修课,每年春季学期,授课对象:全校本科生(西北工业大学课程思政示范课程)</li>


<li>
《计算机视觉》,专业选修课,32学时 (西北工业大学研究生培养质量提升工程建设-课程思政类项目)</li>



<li>
指导研究生获得2022研电赛获得西北赛区一等奖</li>


<li>
计算机学院人工智能课程团队负责人</li>

</ul>

</div> -->



</body>
